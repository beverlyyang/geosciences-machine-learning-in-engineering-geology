{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00df0dfe",
   "metadata": {},
   "source": [
    "# Model 3b - MLPRegressor with standardization & hyperparameter tuning (with 5-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bcbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_validate\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8146d919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wedge ID</th>\n",
       "      <th>Safety Factor</th>\n",
       "      <th>Ln Safety Factor</th>\n",
       "      <th>Safety Factor Class</th>\n",
       "      <th>Safety Factor Class_1</th>\n",
       "      <th>Safety Factor Class_2</th>\n",
       "      <th>Ln Safety Factor Class_2</th>\n",
       "      <th>Wedge Volume (m3)</th>\n",
       "      <th>Wedge Weight (MN)</th>\n",
       "      <th>Plunge Line of Intersection (°)</th>\n",
       "      <th>...</th>\n",
       "      <th>Water Pressure Joint 2 (MPa)</th>\n",
       "      <th>Water Pressure Basal Joint (MPa)</th>\n",
       "      <th>Water Pressure Tension Crack (MPa)</th>\n",
       "      <th>Ponded Water Depth (m)</th>\n",
       "      <th>Seismic Alpha</th>\n",
       "      <th>Seismic Plunge (°)</th>\n",
       "      <th>Seismic Trend (°)</th>\n",
       "      <th>Maximum Persistence Joint 1 (m)</th>\n",
       "      <th>Maximum Persistence Joint 2 (m)</th>\n",
       "      <th>Maximum Persistence Basal Joint (m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFA 60 [0]</td>\n",
       "      <td>1.082239</td>\n",
       "      <td>0.079032</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>6349.248707</td>\n",
       "      <td>171.429715</td>\n",
       "      <td>31.846178</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFA 60 [1]</td>\n",
       "      <td>1.203906</td>\n",
       "      <td>0.185571</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.293893</td>\n",
       "      <td>7701.148241</td>\n",
       "      <td>207.931003</td>\n",
       "      <td>31.905513</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFA 60 [2]</td>\n",
       "      <td>0.896601</td>\n",
       "      <td>-0.109144</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.308093</td>\n",
       "      <td>2341.641868</td>\n",
       "      <td>63.224330</td>\n",
       "      <td>36.973415</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFA 60 [3]</td>\n",
       "      <td>0.680996</td>\n",
       "      <td>-0.384199</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.308093</td>\n",
       "      <td>155.345062</td>\n",
       "      <td>4.194317</td>\n",
       "      <td>54.969435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFA 60 [4]</td>\n",
       "      <td>1.263948</td>\n",
       "      <td>0.234240</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.293893</td>\n",
       "      <td>7468.340623</td>\n",
       "      <td>201.645197</td>\n",
       "      <td>29.688564</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wedge ID  Safety Factor  Ln Safety Factor  Safety Factor Class  \\\n",
       "0  BFA 60 [0]       1.082239          0.079032                 11.0   \n",
       "1  BFA 60 [1]       1.203906          0.185571                 13.0   \n",
       "2  BFA 60 [2]       0.896601         -0.109144                  9.0   \n",
       "3  BFA 60 [3]       0.680996         -0.384199                  7.0   \n",
       "4  BFA 60 [4]       1.263948          0.234240                 13.0   \n",
       "\n",
       "   Safety Factor Class_1  Safety Factor Class_2  Ln Safety Factor Class_2  \\\n",
       "0                    6.0                   1.05                  0.038481   \n",
       "1                    7.0                   1.35                  0.293893   \n",
       "2                    5.0                   0.75                 -0.308093   \n",
       "3                    4.0                   0.75                 -0.308093   \n",
       "4                    7.0                   1.35                  0.293893   \n",
       "\n",
       "   Wedge Volume (m3)  Wedge Weight (MN)  Plunge Line of Intersection (°)  ...  \\\n",
       "0        6349.248707         171.429715                        31.846178  ...   \n",
       "1        7701.148241         207.931003                        31.905513  ...   \n",
       "2        2341.641868          63.224330                        36.973415  ...   \n",
       "3         155.345062           4.194317                        54.969435  ...   \n",
       "4        7468.340623         201.645197                        29.688564  ...   \n",
       "\n",
       "   Water Pressure Joint 2 (MPa)  Water Pressure Basal Joint (MPa)  \\\n",
       "0                           NaN                               NaN   \n",
       "1                           NaN                               NaN   \n",
       "2                           NaN                               NaN   \n",
       "3                           NaN                               NaN   \n",
       "4                           NaN                               NaN   \n",
       "\n",
       "   Water Pressure Tension Crack (MPa)  Ponded Water Depth (m)  Seismic Alpha  \\\n",
       "0                                 NaN                     NaN            NaN   \n",
       "1                                 NaN                     NaN            NaN   \n",
       "2                                 NaN                     NaN            NaN   \n",
       "3                                 NaN                     NaN            NaN   \n",
       "4                                 NaN                     NaN            NaN   \n",
       "\n",
       "   Seismic Plunge (°)  Seismic Trend (°)  Maximum Persistence Joint 1 (m)  \\\n",
       "0                 NaN                NaN                                0   \n",
       "1                 NaN                NaN                                0   \n",
       "2                 NaN                NaN                                0   \n",
       "3                 NaN                NaN                                0   \n",
       "4                 NaN                NaN                                0   \n",
       "\n",
       "   Maximum Persistence Joint 2 (m)  Maximum Persistence Basal Joint (m)  \n",
       "0                                0                                  NaN  \n",
       "1                                0                                  NaN  \n",
       "2                                0                                  NaN  \n",
       "3                                0                                  NaN  \n",
       "4                                0                                  NaN  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "parentdir = os.path.dirname(os.getcwd())\n",
    "data = pd.read_excel(parentdir+'\\\\Data\\\\SWedge Results.xlsx',sheet_name = \"Probabilistic Values\", engine='openpyxl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6103321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63b116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Safety Factor</th>\n",
       "      <th>Dip of Joint 1 (°)</th>\n",
       "      <th>Dip Direction of Joint 1 (°)</th>\n",
       "      <th>Dip of Joint 2 (°)</th>\n",
       "      <th>Dip Direction of Joint 2 (°)</th>\n",
       "      <th>Dip of Slope (°)</th>\n",
       "      <th>Dip Direction of Slope (°)</th>\n",
       "      <th>Friction Angle of Joint 1 (°)</th>\n",
       "      <th>Friction Angle of Joint 2 (°)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.082239</td>\n",
       "      <td>39.265808</td>\n",
       "      <td>120.865923</td>\n",
       "      <td>51.646228</td>\n",
       "      <td>221.979277</td>\n",
       "      <td>58.840543</td>\n",
       "      <td>182.626968</td>\n",
       "      <td>29.567773</td>\n",
       "      <td>29.522638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.203906</td>\n",
       "      <td>38.981309</td>\n",
       "      <td>128.836961</td>\n",
       "      <td>57.766382</td>\n",
       "      <td>235.428421</td>\n",
       "      <td>63.804918</td>\n",
       "      <td>181.820235</td>\n",
       "      <td>32.713619</td>\n",
       "      <td>29.079492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896601</td>\n",
       "      <td>42.032968</td>\n",
       "      <td>117.504566</td>\n",
       "      <td>62.427355</td>\n",
       "      <td>217.726775</td>\n",
       "      <td>58.134485</td>\n",
       "      <td>180.398207</td>\n",
       "      <td>29.660213</td>\n",
       "      <td>27.455866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680996</td>\n",
       "      <td>69.264568</td>\n",
       "      <td>137.906910</td>\n",
       "      <td>66.183726</td>\n",
       "      <td>246.195109</td>\n",
       "      <td>61.968796</td>\n",
       "      <td>182.439496</td>\n",
       "      <td>30.866657</td>\n",
       "      <td>34.401616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.263948</td>\n",
       "      <td>46.728166</td>\n",
       "      <td>121.226945</td>\n",
       "      <td>50.803809</td>\n",
       "      <td>241.060589</td>\n",
       "      <td>60.832522</td>\n",
       "      <td>179.091174</td>\n",
       "      <td>28.789453</td>\n",
       "      <td>28.613525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Safety Factor  Dip of Joint 1 (°)  Dip Direction of Joint 1 (°)  \\\n",
       "0       1.082239           39.265808                    120.865923   \n",
       "1       1.203906           38.981309                    128.836961   \n",
       "2       0.896601           42.032968                    117.504566   \n",
       "3       0.680996           69.264568                    137.906910   \n",
       "4       1.263948           46.728166                    121.226945   \n",
       "\n",
       "   Dip of Joint 2 (°)  Dip Direction of Joint 2 (°)  Dip of Slope (°)  \\\n",
       "0           51.646228                    221.979277         58.840543   \n",
       "1           57.766382                    235.428421         63.804918   \n",
       "2           62.427355                    217.726775         58.134485   \n",
       "3           66.183726                    246.195109         61.968796   \n",
       "4           50.803809                    241.060589         60.832522   \n",
       "\n",
       "   Dip Direction of Slope (°)  Friction Angle of Joint 1 (°)  \\\n",
       "0                  182.626968                      29.567773   \n",
       "1                  181.820235                      32.713619   \n",
       "2                  180.398207                      29.660213   \n",
       "3                  182.439496                      30.866657   \n",
       "4                  179.091174                      28.789453   \n",
       "\n",
       "   Friction Angle of Joint 2 (°)  \n",
       "0                      29.522638  \n",
       "1                      29.079492  \n",
       "2                      27.455866  \n",
       "3                      34.401616  \n",
       "4                      28.613525  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data specifically for the modelling (i.e., the inputs and output)\n",
    "data_model = data[[\"Safety Factor\",\"Dip of Joint 1 (°)\",\"Dip Direction of Joint 1 (°)\",\"Dip of Joint 2 (°)\",\"Dip Direction of Joint 2 (°)\",\"Dip of Slope (°)\",\"Dip Direction of Slope (°)\",\"Friction Angle of Joint 1 (°)\",\"Friction Angle of Joint 2 (°)\"]]\n",
    "print(np.shape(data_model))\n",
    "data_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cae351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4992, 9)\n"
     ]
    }
   ],
   "source": [
    "# remove any realizations that are not kinematically possible and any duplicates\n",
    "data_model =  data_model.dropna()\n",
    "data_model = data_model.drop_duplicates()\n",
    "print(np.shape(data_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f792917",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fcf46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlpregressor__hidden_layer_sizes': [(10,), (15,), (20,), (10, 10), (15, 10), (20, 10)], 'mlpregressor__activation': ['tanh', 'relu'], 'mlpregressor__solver': ['sgd', 'adam'], 'mlpregressor__alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'mlpregressor__learning_rate_init': [0.001, 0.01, 0.1], 'mlpregressor__max_iter': [200, 500]}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter grid for MLPRegressor\n",
    "# number of neurons in hidden layer(s)\n",
    "# note: 1 hidden layer - > (x,), 2 hidden layers -> (x,y), 3 hidden layers -> (x,y,z), etc\n",
    "hidden_layer_sizes = [(10,),(15,),(20,),(10,10),(15,10),(20,10)]\n",
    "\n",
    "# activation function for hidden layer\n",
    "activation = ['tanh','relu']\n",
    "\n",
    "# solver for weight optimization\n",
    "solver = ['sgd','adam']\n",
    "\n",
    "# alpha (strength of L2 regularization term)\n",
    "# https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html\n",
    "alpha = [0.0001,0.001,0.01,0.1,1]\n",
    "\n",
    "# initial learning rate\n",
    "learning_rate_init = [0.001,0.01,0.1]\n",
    "\n",
    "# maximum number of iterations\n",
    "max_iter = [200,500]\n",
    "\n",
    "\n",
    "# create the random grid\n",
    "param_grid = {'mlpregressor__hidden_layer_sizes': hidden_layer_sizes,\n",
    "              'mlpregressor__activation': activation,\n",
    "              'mlpregressor__solver': solver,\n",
    "              'mlpregressor__alpha': alpha,\n",
    "              'mlpregressor__learning_rate_init': learning_rate_init,\n",
    "              'mlpregressor__max_iter': max_iter}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d1ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state=123, early_stopping=True, validation_fraction=0.2\n",
    "\n",
    "# function to get train & test r2 and RMSE for specified dataset size where hyperparameter tuning was performed\n",
    "def hyperparam_results(data, dataset_size, param_grid):\n",
    "    random_state_val = [0,1,42,123]\n",
    "    param_grid = param_grid\n",
    "    \n",
    "    r2_train_subsample_list = []\n",
    "    rmse_train_subsample_list = []\n",
    "    mape_train_subsample_list = []\n",
    "    r2_test_subsample_list = []\n",
    "    rmse_test_subsample_list = []\n",
    "    mape_test_subsample_list = []\n",
    "\n",
    "\n",
    "    for x in range(0,4):\n",
    "        # get subsample of data\n",
    "        data_subsample = data_model.sample(n = dataset_size,random_state = 1)\n",
    "\n",
    "        # train/test split with different random_state values (0, 1, 42, and 123)\n",
    "        train_subsample, test_subsample = train_test_split(data_subsample, test_size=0.2, random_state=random_state_val[x])\n",
    "\n",
    "        x_train_subsample = train_subsample[[\"Dip of Joint 1 (°)\",\"Dip Direction of Joint 1 (°)\",\"Dip of Joint 2 (°)\",\"Dip Direction of Joint 2 (°)\",\"Dip of Slope (°)\",\"Dip Direction of Slope (°)\",\"Friction Angle of Joint 1 (°)\",\"Friction Angle of Joint 2 (°)\"]]\n",
    "        y_train_subsample = train_subsample[[\"Safety Factor\"]]\n",
    "        y_train_subsample = np.ravel(y_train_subsample)\n",
    "\n",
    "        x_test_subsample = test_subsample[[\"Dip of Joint 1 (°)\",\"Dip Direction of Joint 1 (°)\",\"Dip of Joint 2 (°)\",\"Dip Direction of Joint 2 (°)\",\"Dip of Slope (°)\",\"Dip Direction of Slope (°)\",\"Friction Angle of Joint 1 (°)\",\"Friction Angle of Joint 2 (°)\"]]\n",
    "        y_test_subsample = test_subsample[[\"Safety Factor\"]]\n",
    "        y_test_subsample = np.ravel(y_test_subsample)\n",
    "\n",
    "        # hyperparameter tuning\n",
    "        # make pipeline for MLPRegressor with pre-processing (standardizing the data)\n",
    "        pipe_mlp = make_pipeline(StandardScaler(), MLPRegressor(random_state = 123,early_stopping=True,validation_fraction=0.2))\n",
    "        random_search = RandomizedSearchCV(estimator=pipe_mlp, param_distributions=param_grid,n_iter=100, n_jobs=-1,cv=5,random_state=123)\n",
    "\n",
    "        random_search.fit(x_train_subsample, y_train_subsample)\n",
    "\n",
    "        ypred_mlp = random_search.predict(x_train_subsample)\n",
    "        ypred_mlp = np.reshape(ypred_mlp,(len(ypred_mlp),1))\n",
    "\n",
    "        # training r2 and rmse\n",
    "        r2_train_subsample = random_search.score(x_train_subsample,y_train_subsample)\n",
    "        rmse_train_subsample = math.sqrt(mean_squared_error(y_train_subsample,ypred_mlp))\n",
    "\n",
    "        # append training r2 and rmse to their respective lists\n",
    "        r2_train_subsample_list.append(r2_train_subsample)\n",
    "        rmse_train_subsample_list.append(rmse_train_subsample)\n",
    "\n",
    "\n",
    "        # test the mlp model\n",
    "        # predict y test\n",
    "        ypred_test_mlp = random_search.predict(x_test_subsample)\n",
    "        ypred_test_mlp = np.reshape(ypred_test_mlp,(len(ypred_test_mlp),1))\n",
    "\n",
    "        # test r2 and rmse\n",
    "        r2_test_subsample = random_search.score(x_test_subsample,y_test_subsample)\n",
    "        rmse_test_subsample = math.sqrt(mean_squared_error(y_test_subsample,ypred_test_mlp))\n",
    "\n",
    "        # append test r2 and rmse to their respective lists\n",
    "        r2_test_subsample_list.append(r2_test_subsample)\n",
    "        rmse_test_subsample_list.append(rmse_test_subsample)\n",
    "        \n",
    "    return r2_train_subsample_list,rmse_train_subsample_list,r2_test_subsample_list,rmse_test_subsample_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1e1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 100 data points\n",
    "R2_train_100, rmse_train_100, R2_test_100, rmse_test_100 = hyperparam_results(data_model,100,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519f0d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08880191378892821, 0.21278154032706964, 0.3788140215105845, 0.5206115440760606]\n",
      "[0.4610277028308095, 0.336503760385949, 0.8878916610174372, 0.8108884929303347]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 100 data points for four different random_state values in train/test split\n",
    "print(R2_train_100)\n",
    "print(R2_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caec0184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2578695874090826, 1.1912412647157131, 1.0547549499571574, 0.932254448939627]\n",
      "[0.4953782619824308, 0.3517017265836818, 0.16653704959200247, 0.17014629789372207]\n"
     ]
    }
   ],
   "source": [
    "# training and test rmse for MLP trained on 100 data points for four different random_state values in train/test split\n",
    "print(rmse_train_100)\n",
    "print(rmse_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d565b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37222579 -0.12372222 -0.50907764 -0.29027695]\n",
      "[-0.76249133 -0.83953954 -0.8882179  -0.76210815]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 100 data points for four different random_state values in train/test split\n",
    "R2_diff_100 = np.asarray(R2_train_100) - np.asarray(R2_test_100)\n",
    "print(R2_diff_100)\n",
    "\n",
    "# test - train rmse for MLP trained on 100 data points for four different random_state values in train/test split\n",
    "rmse_diff_100 = np.asarray(rmse_test_100) - np.asarray(rmse_train_100)\n",
    "print(rmse_diff_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0520d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 150 data points\n",
    "R2_train_150, rmse_train_150, R2_test_150, rmse_test_150 = hyperparam_results(data_model,150,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c65fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5377828361885109, 0.858264506079799, 0.9146103560868711, 0.5428705971237759]\n",
      "[0.8693453216302964, 0.017351872947760083, 0.37318327591327405, -1.144291718987422]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 150 data points for four different random_state values in train/test split\n",
    "print(R2_train_150)\n",
    "print(R2_test_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0069edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7495254924504497, 0.4307083169548325, 0.14352757438532934, 0.7758513321510008]\n",
      "[0.2587050146702111, 0.36928090039131917, 1.642216631665191, 0.440499398252651]\n"
     ]
    }
   ],
   "source": [
    "# training and test rmse for MLP trained on 150 data points for four different random_state values in train/test split\n",
    "print(rmse_train_150)\n",
    "print(rmse_test_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5634c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33156249  0.84091263  0.54142708  1.68716232]\n",
      "[-0.49082048 -0.06142742  1.49868906 -0.33535193]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 150 data points for four different random_state values in train/test split\n",
    "R2_diff_150 = np.asarray(R2_train_150) - np.asarray(R2_test_150)\n",
    "print(R2_diff_150)\n",
    "\n",
    "# test - train rmse for MLP trained on 150 data points for four different random_state values in train/test split\n",
    "rmse_diff_150 = np.asarray(rmse_test_150) - np.asarray(rmse_train_150)\n",
    "print(rmse_diff_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e02a8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 200 data points\n",
    "R2_train_200, rmse_train_200, R2_test_200, rmse_test_200 = hyperparam_results(data_model,200,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44035e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5610662938403107, 0.8542533123403682, 0.5656799772719978, 0.9894214501206057]\n",
      "[0.2357732259128491, 0.4887406444960761, 0.8490924652686006, 0.8846778080267299]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 200 data points for four different random_state values in train/test split\n",
    "print(R2_train_200)\n",
    "print(R2_test_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce607023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6768637729817131, 0.38445210483726827, 0.6637023500374829, 0.10526056817756295]\n",
      "[0.30318085310710674, 0.348346770639324, 0.18687763298019194, 0.09445844567665601]\n"
     ]
    }
   ],
   "source": [
    "# training and test rmse for MLP trained on 200 data points for four different random_state values in train/test split\n",
    "print(rmse_train_200)\n",
    "print(rmse_test_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a892af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32529307  0.36551267 -0.28341249  0.10474364]\n",
      "[-0.37368292 -0.03610533 -0.47682472 -0.01080212]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 200 data points for four different random_state values in train/test split\n",
    "R2_diff_200 = np.asarray(R2_train_200) - np.asarray(R2_test_200)\n",
    "print(R2_diff_200)\n",
    "\n",
    "# test - train rmse for MLP trained on 200 data points for four different random_state values in train/test split\n",
    "rmse_diff_200 = np.asarray(rmse_test_200) - np.asarray(rmse_train_200)\n",
    "print(rmse_diff_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ffa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 250 data points\n",
    "R2_train_250, rmse_train_250, R2_test_250, rmse_test_250 = hyperparam_results(data_model,250,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b62ab9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9227686825125857, 0.5365414871107412, 0.45399371924840837, 0.9877708529986308]\n",
      "[0.45104057762068106, 0.6007185401404103, 0.5121167492337805, 0.6861621349687117]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 250 data points for four different random_state values in train/test split\n",
    "print(R2_train_250)\n",
    "print(R2_test_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e63a1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12665168759716375, 0.6253237869176014, 0.6863015664155884, 0.1019052058821934]\n",
      "[1.2182101533482979, 0.2892710403825874, 0.23764082047170867, 0.24348886627584143]\n"
     ]
    }
   ],
   "source": [
    "# training and test rmse for MLP trained on 250 data points for four different random_state values in train/test split\n",
    "print(rmse_train_250)\n",
    "print(rmse_test_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b0c3454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4717281  -0.06417705 -0.05812303  0.30160872]\n",
      "[ 1.09155847 -0.33605275 -0.44866075  0.14158366]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 250 data points for four different random_state values in train/test split\n",
    "R2_diff_250 = np.asarray(R2_train_250) - np.asarray(R2_test_250)\n",
    "print(R2_diff_250)\n",
    "\n",
    "# test - train rmse for MLP trained on 250 data points for four different random_state values in train/test split\n",
    "rmse_diff_250 = np.asarray(rmse_test_250) - np.asarray(rmse_train_250)\n",
    "print(rmse_diff_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7dce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 750 data points\n",
    "R2_train_750, rmse_train_750, R2_test_750, rmse_test_750 = hyperparam_results(data_model,750,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7094b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9484341405362441, 0.8225793604962152, 0.7655013975365361, 0.9936981885032529]\n",
      "[0.5608251274943824, 0.8860252015950263, 0.9875852261784479, 0.6721198130503282]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 750 data points for four different random_state values in train/test split\n",
    "print(R2_train_750)\n",
    "print(R2_test_750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a621edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10754552867796552, 0.2752773833411017, 0.3088124044551475, 0.03624086670069489]\n",
      "[0.6639628285456566, 0.14805862493255323, 0.058246557480081056, 0.5915301963653623]\n"
     ]
    }
   ],
   "source": [
    "# training and test rmse for MLP trained on 750 data points for four different random_state values in train/test split\n",
    "print(rmse_train_750)\n",
    "print(rmse_test_750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13474fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38760901 -0.06344584 -0.22208383  0.32157838]\n",
      "[ 0.5564173  -0.12721876 -0.25056585  0.55528933]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 750 data points for four different random_state values in train/test split\n",
    "R2_diff_750 = np.asarray(R2_train_750) - np.asarray(R2_test_750)\n",
    "print(R2_diff_750)\n",
    "\n",
    "# test - train rmse for MLP trained on 750 data points for four different random_state values in train/test split\n",
    "rmse_diff_750 = np.asarray(rmse_test_750) - np.asarray(rmse_train_750)\n",
    "print(rmse_diff_750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f5aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model results for dataset size = 200 data points\n",
    "R2_train_2000, rmse_train_2000, R2_test_2000, rmse_test_2000 = hyperparam_results(data_model,2000,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce00ae6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.910865945281249, 0.9435426456174045, 0.9382160514998862, 0.993370371335103]\n",
      "[0.959021557483769, 0.9287069888345919, 0.8939300052698967, 0.8442070577197893]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 2000 data points for four different random_state values in train/test split\n",
    "print(R2_train_2000)\n",
    "print(R2_test_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d95dc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16121762933486083, 0.13188980297082653, 0.13942003646241952, 0.039093591955569114]\n",
      "[0.11085155628294135, 0.1291676998823314, 0.148530384664726, 0.2912193850503976]\n"
     ]
    }
   ],
   "source": [
    "# training and test r2 for MLP trained on 2000 data points for four different random_state values in train/test split\n",
    "print(rmse_train_2000)\n",
    "print(rmse_test_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73c02a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04815561  0.01483566  0.04428605  0.14916331]\n",
      "[-0.05036607 -0.0027221   0.00911035  0.25212579]\n"
     ]
    }
   ],
   "source": [
    "# train - test r2 for MLP trained on 2000 data points for four different random_state values in train/test split\n",
    "R2_diff_2000 = np.asarray(R2_train_2000) - np.asarray(R2_test_2000)\n",
    "print(R2_diff_2000)\n",
    "\n",
    "# test - train rmse for MLP trained on 2000 data points for four different random_state values in train/test split\n",
    "rmse_diff_2000 = np.asarray(rmse_test_2000) - np.asarray(rmse_train_2000)\n",
    "print(rmse_diff_2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
